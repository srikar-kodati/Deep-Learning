{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs = {}):\n",
    "        if(logs.get('accuracy')>0.9):\n",
    "            print(\"\\nReached optimal accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth = 200)\n",
    "import matplotlib.pyplot as plt\n",
    "#Disaplay the first image in training\n",
    "plt.imshow(X_test[0])\n",
    "print(y_train[0])\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values of image are numbers between 0 and 255. To normalize this we have to have very number betwen 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last layer has 10 nuerons because there are 10 classes of clothing (labels) in dataset\n",
    "First layer flattens the square into a linear array. Square is input image size 28X28\n",
    "\n",
    "Relu effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
    "\n",
    "Softmax takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4787 - accuracy: 0.8310\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3600 - accuracy: 0.8681\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3211 - accuracy: 0.8812\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.2981 - accuracy: 0.8888\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2791 - accuracy: 0.8968\n",
      "Epoch 6/10\n",
      "59680/60000 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9021\n",
      "Reached optimal accuracy so cancelling training!\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2637 - accuracy: 0.9021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c2cfdda148>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,epochs = 10, callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 39us/sample - loss: 0.3347 - accuracy: 0.8810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3347362241744995, 0.881]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
